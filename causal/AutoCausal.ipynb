{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "# data processing packages\n",
    "import numpy as np   \n",
    "import pandas as pd \n",
    "import scipy as sp\n",
    "\n",
    "import pylab\n",
    "\n",
    "from pandas import *\n",
    "from numpy import *\n",
    "from scipy import *\n",
    "\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# machine leanring packages\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# own utilities\n",
    "from utils_dataPrepro import *\n",
    "# from ml_models import *\n",
    "#from utils_keras import *\n",
    "\n",
    "# statiscal models\n",
    "import statsmodels as sm\n",
    "from statsmodels.tsa.stattools import acf  \n",
    "from statsmodels.tsa.stattools import pacf\n",
    "from statsmodels.tsa.api import VAR, DynamicVAR\n",
    "\n",
    "from statsmodels.stats import diagnostic\n",
    "\n",
    "\n",
    "# visulization\n",
    "%matplotlib inline    \n",
    "import matplotlib as mplt\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import IPython\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRANGER CAUSALITY\n",
    "\n",
    "# http://davegiles.blogspot.ch/2011/04/testing-for-granger-causality.html\n",
    "# https://menghublog.wordpress.com/2014/08/27/error-correction-model-in-time-series-regression/\n",
    "\n",
    "# TO DO:\n",
    "# consider the co-integration lag \n",
    "\n",
    "\n",
    "# Johansen's methodology (based on your VAR) for a reliable result\n",
    "    \n",
    "# In statistics, the Johansen test,[1] named after SÃ¸ren Johansen, \n",
    "# is a procedure \n",
    "# for testing cointegration of several, say k, I(1) time series.\n",
    "\n",
    "# Non-causality test \n",
    "\n",
    "# Seasonality test \n",
    "\n",
    "# Causality in seansonal data \n",
    "\n",
    "# http://davegiles.blogspot.ch/2015/03/granger-causality-seasonal-adjustment.html\n",
    "\n",
    "# https://www.otexts.org/fpp/8/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37800, 6) (5999, 6)\n"
     ]
    }
   ],
   "source": [
    "# dataset_str = str(sys.argv[1])\n",
    "# print \"Load dataset %s\"%dataset_str\n",
    "\n",
    "dataset_str = \"pm25\"\n",
    "\n",
    "file_dic = { \"stock\":0,\\\n",
    "             \"power\":1,\\\n",
    "             \"air\":2,\\\n",
    "             \"pm25\":3\n",
    "           }\n",
    "\n",
    "files_list=[]\n",
    "files_list.append( [\"../../dataset/dataset_ts/stock_xtrain.dat\", \\\n",
    "            \"../../dataset/dataset_ts/stock_xtest.dat\"] )\n",
    "                    \n",
    "files_list.append( [\"../../dataset/dataset_ts/power_xtrain.dat\", \\\n",
    "            \"../../dataset/dataset_ts/power_xtest.dat\"] )\n",
    "                    \n",
    "files_list.append( [\"../../dataset/dataset_ts/air_xtrain.dat\", \\\n",
    "            \"../../dataset/dataset_ts/air_xtest.dat\"] )\n",
    "\n",
    "files_list.append( [\"../../dataset/dataset_ts/pm25_xtrain.dat\", \\\n",
    "            \"../../dataset/dataset_ts/pm25_xtest.dat\"] )\n",
    "\n",
    "\n",
    "xtr = np.load(files_list[ file_dic[dataset_str] ][0])\n",
    "xts = np.load(files_list[ file_dic[dataset_str] ][1])\n",
    "\n",
    "# xtrain, xtest, _, _ = \\\n",
    "# prepare_train_test_data( False, files_list[ file_dic[dataset_str] ])\n",
    "\n",
    "print np.shape(xtr), np.shape(xts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ts_stationarize_diff( ts ):\n",
    "    \n",
    "    cur_ts = ts\n",
    "    \n",
    "    p_val = sm.tsa.stattools.adfuller(cur_ts,\\\n",
    "                                      regression='c', \\\n",
    "                                      maxlag=None, store=False)[1]\n",
    "    diff_cnt = 0 \n",
    "    while p_val > 0.01:\n",
    "                \n",
    "        pre_ts = cur_ts[1:]\n",
    "        post_ts = cur_ts[:-1]\n",
    "        \n",
    "        diff_cnt += 1\n",
    "        \n",
    "        tmplen= len(pre_ts)\n",
    "        \n",
    "        cur_ts = [ pre_ts[i] - post_ts[i] for i in range(tmplen) ] \n",
    "        \n",
    "        p_val = sm.tsa.stattools.adfuller(cur_ts,\\\n",
    "                                          regression='c', \\\n",
    "                                          maxlag=None, store=False)[1]\n",
    "        \n",
    "    return diff_cnt, p_val, cur_ts\n",
    "\n",
    "def multi_ts_stationarize( dta ):\n",
    "    \n",
    "    post_len = []\n",
    "    post_dta = []\n",
    "    \n",
    "    num_ts = len(dta[0])\n",
    "    len_ts = len(dta)\n",
    "     \n",
    "    for i in range(num_ts):\n",
    "        tmpts = [ dta[j][i] for j in range(len_ts) ]\n",
    "        tmpts = ts_stationarize_diff( tmpts )\n",
    "        \n",
    "        print \"stationary prepro: \", tmpts[0], tmpts[1], '\\n'\n",
    "        \n",
    "        post_len.append( len(tmpts[2]) )\n",
    "        post_dta.append( tmpts[2] )\n",
    "        \n",
    "    min_len = min(post_len)\n",
    "        \n",
    "    res_dta = []\n",
    "    for i in range(num_ts):\n",
    "        res_dta.append( post_dta[i][ post_len[i]-min_len : post_len[i] ] )\n",
    "        \n",
    "    return np.transpose(res_dta,[1, 0])\n",
    "\n",
    "def causality_VAR(post_ts):\n",
    "    \n",
    "    model =  VAR(xtr)\n",
    "    best_lag = model.select_order(60, verbose= False)\n",
    "    \n",
    "    print 'best lag: ', best_lag\n",
    "    \n",
    "    result = model.fit(best_lag['aic'])\n",
    "    \n",
    "    return result, best_lag\n",
    "\n",
    "def causality_pairwise(VAR_res, post_ts):\n",
    "    \n",
    "    num_ts = len(post_ts[0])\n",
    "    \n",
    "    causing = []\n",
    "    \n",
    "    for i in range(num_ts):\n",
    "        causing.append( [] )\n",
    "        \n",
    "        for j in range(num_ts):\n",
    "            if j!=i:\n",
    "                tmp_res = VAR_res.test_causality(i, [j], kind='wald', \\\n",
    "                                                verbose=False)\n",
    "                \n",
    "                if tmp_res['pvalue']< 0.01:\n",
    "                    causing[-1].append(j)\n",
    "    \n",
    "    return causing\n",
    "\n",
    "def causality_one(VAR_res, post_ts, ts_id):\n",
    "    \n",
    "    num_ts = len(post_ts[0])\n",
    "    causing = []\n",
    "        \n",
    "    for j in range(num_ts):\n",
    "        if j != ts_id:\n",
    "            tmp_res = VAR_res.test_causality(ts_id, [j], kind='wald', \\\n",
    "                                                verbose=False)\n",
    "                \n",
    "            if tmp_res['pvalue']< 0.01:\n",
    "                causing.append(j)\n",
    "    \n",
    "    return causing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stationary prepro:  0 1.52193882293e-07 \n",
      "\n",
      "stationary prepro:  0 0.00342085835112 \n",
      "\n",
      "stationary prepro:  0 7.8946082556e-11 \n",
      "\n",
      "stationary prepro:  0 0.0 \n",
      "\n",
      "stationary prepro:  0 0.0 \n",
      "\n",
      "stationary prepro:  0 0.0 \n",
      "\n",
      "best lag:  {'fpe': 54, 'hqic': 30, 'bic': 26, 'aic': 54}\n",
      "[[1, 2, 5], [0, 2, 3, 5], [0, 1, 3, 5], [0, 1, 2], [5], [0, 1, 2]]\n"
     ]
    }
   ],
   "source": [
    "post_ts = multi_ts_stationarize( xtr )\n",
    "    \n",
    "VAR_res,lag = causality_VAR(post_ts)\n",
    "            \n",
    "print causality_pairwise(VAR_res, post_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n"
     ]
    }
   ],
   "source": [
    "print causality_one(VAR_res, post_ts, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 8)\n"
     ]
    }
   ],
   "source": [
    "pred_x = VAR_res.forecast(xtr[-lag['aic']:], 5)\n",
    "print np.shape(pred_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Causality test via VAR\n",
    "\n",
    "def VAR_lag_selection( ts_df, max_lag):\n",
    "    \n",
    "    min_aic = np.inf\n",
    "    min_lag = 0\n",
    "    min_result = []\n",
    "    \n",
    "    for i in range(1,max_lag+1):\n",
    "        model = VAR(ts_df)\n",
    "        results = model.fit(i)\n",
    "        \n",
    "        aic = results.aic\n",
    "        \n",
    "        if aic<min_aic:\n",
    "            min_lag = i\n",
    "            min_aic = aic\n",
    "            min_result = results\n",
    "    \n",
    "#     print min_result.summary()\n",
    "    return min_lag, min_aic, min_result\n",
    "\n",
    "# built-in lag order selection\n",
    "model =  VAR(xtr)\n",
    "\n",
    "best_lag = model.select_order(60, verbose= False)\n",
    "print 'best lag: ', best_lag\n",
    "\n",
    "result = model.fit(best_lag['aic'])\n",
    "\n",
    "\n",
    "print result.test_causality(0, [1], kind='wald')\n",
    "\n",
    "print '\\n'\n",
    "\n",
    "print result.test_causality(1, [0], kind='f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Causality test via direct built-in routine  \n",
    "\n",
    "# The Null hypothesis for grangercausalitytests is \n",
    "# that the time series in the second column, x2, \n",
    "# does NOT Granger cause the time series in the first column, x1. \n",
    "\n",
    "# The null hypothesis for all four test is that the \n",
    "# coefficients corresponding to past values of the second \n",
    "# time series are zero.\n",
    "\n",
    "maxlag = 5\n",
    "res = sm.tsa.stattools.grangercausalitytests(xtr, maxlag,\\\n",
    "                                addconst=True, verbose=False)\n",
    "\n",
    "for i in range(1, maxlag+1):\n",
    "    print res[i][0], '\\n'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
